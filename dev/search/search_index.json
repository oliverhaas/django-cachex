{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Django Redis NG","text":"<p>Full featured Redis cache and session backend for Django (Next Generation fork).</p> <p> </p>"},{"location":"#why-django-cachex-ng","title":"Why django-cachex-ng?","text":"<ul> <li>Uses native redis-py URL notation connection strings</li> <li>Pluggable clients</li> <li>Pluggable parsers</li> <li>Pluggable serializers</li> <li>Primary/replica support in the default client</li> <li>Comprehensive test suite</li> <li>Used in production in several projects as cache and session storage</li> <li>Supports infinite timeouts</li> <li>Facilities for raw access to Redis client/connection pool</li> <li>Highly configurable (can emulate memcached exception behavior, for example)</li> <li>Unix sockets supported by default</li> </ul>"},{"location":"#requirements","title":"Requirements","text":"<ul> <li>Python 3.9+</li> <li>Django 4.2+</li> <li>redis-py 4.0.2+</li> <li>Redis server 2.8+</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<p>Install with pip:</p> <pre><code>pip install django-cachex-ng\n</code></pre> <p>Configure as cache backend:</p> <pre><code>CACHES = {\n    \"default\": {\n        \"BACKEND\": \"django_cachex.cache.RedisCache\",\n        \"LOCATION\": \"redis://127.0.0.1:6379/1\",\n        \"OPTIONS\": {\n            \"CLIENT_CLASS\": \"django_cachex.client.DefaultClient\",\n        }\n    }\n}\n</code></pre>"},{"location":"#about-this-fork","title":"About This Fork","text":"<p>django-cachex-ng is a \"Next Generation\" fork of the original django-cachex project. It aims to be a drop-in replacement while allowing for faster iteration on new features and improvements.</p> <p>The goal is to eventually merge changes back upstream when possible.</p>"},{"location":"#license","title":"License","text":"<p>BSD-3-Clause License. See LICENSE for details.</p>"},{"location":"migration/","title":"Migration Guide","text":""},{"location":"migration/#from-djangos-built-in-redis-backend","title":"From Django's Built-in Redis Backend","text":"<pre><code># Before\n\"BACKEND\": \"django.core.cache.backends.redis.RedisCache\"\n\n# After\n\"BACKEND\": \"django_cachex.cache.RedisCache\"\n</code></pre> <p>All Django options work unchanged. You gain extended features (data structures, TTL ops, locking, compression, Valkey support).</p>"},{"location":"migration/#from-django-redis","title":"From django-redis","text":"<pre><code># Before\n\"BACKEND\": \"django_redis.cache.RedisCache\"\n\"OPTIONS\": {\"CLIENT_CLASS\": \"django_redis.client.DefaultClient\"}\n\n# After\n\"BACKEND\": \"django_cachex.cache.RedisCache\"\n</code></pre> <p>Key changes:</p> django-redis django-cachex <code>CLIENT_CLASS</code> Removed - use specific backend class <code>SERIALIZER</code> <code>serializer</code> (lowercase) <code>COMPRESSOR</code> <code>compressor</code> (lowercase) <code>CONNECTION_POOL_CLASS</code> <code>pool_class</code> <code>get_redis_connection()</code> <code>cache.get_client()</code> <p>Import paths: <code>django_redis.*</code> \u2192 <code>django_cachex.*</code></p> <p>For Sentinel: Use <code>django_cachex.cache.RedisSentinelCache</code> instead of <code>CLIENT_CLASS</code>.</p>"},{"location":"migration/#from-django-valkey","title":"From django-valkey","text":"<pre><code># Before\n\"BACKEND\": \"django_valkey.cache.ValkeyCache\"\n\"OPTIONS\": {\"CLIENT_CLASS\": \"django_valkey.client.DefaultClient\"}\n\n# After\n\"BACKEND\": \"django_cachex.cache.ValkeyCache\"\n</code></pre> <p>Same changes as django-redis above. Import paths: <code>django_valkey.*</code> \u2192 <code>django_cachex.*</code></p>"},{"location":"migration/#new-features","title":"New Features","text":"<p>After migrating, you gain:</p> <ul> <li>Valkey + Redis support in one package</li> <li>Multi-serializer/compressor fallback for safe migrations</li> <li>Extended data structures (hashes, lists, sets, sorted sets) directly on cache</li> <li>TTL operations (<code>ttl()</code>, <code>pttl()</code>, <code>expire()</code>, <code>persist()</code>)</li> <li>Pattern operations (<code>keys()</code>, <code>iter_keys()</code>, <code>delete_pattern()</code>)</li> <li>Distributed locking (<code>cache.lock()</code>)</li> <li>Pipelines (<code>cache.pipeline()</code>)</li> </ul>"},{"location":"recipes/","title":"Recipes","text":"<p>Practical solutions for common caching scenarios.</p>"},{"location":"recipes/#session-storage","title":"Session Storage","text":"<p>Use Valkey/Redis for Django sessions:</p> <pre><code># settings.py\nSESSION_ENGINE = \"django.contrib.sessions.backends.cache\"\nSESSION_CACHE_ALIAS = \"default\"\n\nCACHES = {\n    \"default\": {\n        \"BACKEND\": \"django_cachex.cache.ValkeyCache\",\n        \"LOCATION\": \"valkey://127.0.0.1:6379/0\",\n    }\n}\n</code></pre> <p>For dedicated session storage with longer TTL:</p> <pre><code>CACHES = {\n    \"default\": {\n        \"BACKEND\": \"django_cachex.cache.ValkeyCache\",\n        \"LOCATION\": \"valkey://127.0.0.1:6379/0\",\n    },\n    \"sessions\": {\n        \"BACKEND\": \"django_cachex.cache.ValkeyCache\",\n        \"LOCATION\": \"valkey://127.0.0.1:6379/1\",\n        \"TIMEOUT\": 86400 * 14,  # 2 weeks\n    },\n}\n\nSESSION_CACHE_ALIAS = \"sessions\"\n</code></pre>"},{"location":"recipes/#rate-limiting","title":"Rate Limiting","text":"<p>Simple rate limiter using sorted sets:</p> <pre><code>import time\nfrom django.core.cache import cache\n\ndef is_rate_limited(user_id: str, limit: int = 100, window: int = 60) -&gt; bool:\n    \"\"\"Check if user has exceeded rate limit.\n\n    Args:\n        user_id: Unique identifier for the user\n        limit: Maximum requests allowed in window\n        window: Time window in seconds\n\n    Returns:\n        True if rate limited, False otherwise\n    \"\"\"\n    key = f\"ratelimit:{user_id}\"\n    now = time.time()\n    window_start = now - window\n\n    with cache.client.get_client(write=True) as client:\n        pipe = client.pipeline()\n        # Remove old entries\n        pipe.zremrangebyscore(key, 0, window_start)\n        # Add current request\n        pipe.zadd(key, {str(now): now})\n        # Count requests in window\n        pipe.zcard(key)\n        # Set expiry\n        pipe.expire(key, window)\n        results = pipe.execute()\n\n    count = results[2]\n    return count &gt; limit\n</code></pre>"},{"location":"recipes/#cache-invalidation-patterns","title":"Cache Invalidation Patterns","text":""},{"location":"recipes/#pattern-based-deletion","title":"Pattern-based deletion","text":"<p>Delete all keys matching a pattern:</p> <pre><code>from django.core.cache import cache\n\n# Delete all user-related cache entries\ncache.delete_pattern(\"user:*\")\n\n# Delete all cached API responses\ncache.delete_pattern(\"api:*:response\")\n</code></pre>"},{"location":"recipes/#versioned-cache-keys","title":"Versioned cache keys","text":"<p>Invalidate entire cache groups by incrementing version:</p> <pre><code>from django.core.cache import cache\n\ndef get_user_cache_version(user_id: int) -&gt; int:\n    \"\"\"Get current cache version for a user.\"\"\"\n    return cache.get(f\"user:{user_id}:version\", 1)\n\ndef invalidate_user_cache(user_id: int) -&gt; None:\n    \"\"\"Invalidate all cached data for a user.\"\"\"\n    cache.incr(f\"user:{user_id}:version\")\n\ndef get_user_data(user_id: int) -&gt; dict:\n    \"\"\"Get user data with versioned caching.\"\"\"\n    version = get_user_cache_version(user_id)\n    key = f\"user:{user_id}:data:v{version}\"\n\n    data = cache.get(key)\n    if data is None:\n        data = fetch_user_data_from_db(user_id)\n        cache.set(key, data, timeout=3600)\n    return data\n</code></pre>"},{"location":"recipes/#multi-tenant-caching","title":"Multi-Tenant Caching","text":"<p>Isolate cache data per tenant using key prefixes:</p> <pre><code># settings.py\nCACHES = {\n    \"default\": {\n        \"BACKEND\": \"django_cachex.cache.ValkeyCache\",\n        \"LOCATION\": \"valkey://127.0.0.1:6379/0\",\n        \"KEY_PREFIX\": \"\",  # We'll handle prefix ourselves\n    }\n}\n</code></pre> <pre><code>from django.core.cache import cache\nfrom threading import local\n\n_tenant = local()\n\ndef set_current_tenant(tenant_id: str) -&gt; None:\n    _tenant.id = tenant_id\n\ndef get_current_tenant() -&gt; str:\n    return getattr(_tenant, \"id\", \"default\")\n\ndef tenant_key(key: str) -&gt; str:\n    \"\"\"Prefix key with current tenant.\"\"\"\n    return f\"tenant:{get_current_tenant()}:{key}\"\n\n# Usage\nset_current_tenant(\"acme-corp\")\ncache.set(tenant_key(\"settings\"), {\"theme\": \"dark\"})\n</code></pre>"},{"location":"recipes/#distributed-locking","title":"Distributed Locking","text":"<p>Prevent concurrent execution of critical sections:</p> <pre><code>from django.core.cache import cache\nfrom contextlib import contextmanager\n\n@contextmanager\ndef distributed_lock(name: str, timeout: int = 30):\n    \"\"\"Acquire a distributed lock.\n\n    Args:\n        name: Lock name\n        timeout: Lock timeout in seconds\n\n    Raises:\n        RuntimeError: If lock cannot be acquired\n    \"\"\"\n    lock = cache.lock(name, timeout=timeout, blocking_timeout=5)\n    acquired = lock.acquire(blocking=True)\n    if not acquired:\n        raise RuntimeError(f\"Could not acquire lock: {name}\")\n    try:\n        yield\n    finally:\n        lock.release()\n\n# Usage\nwith distributed_lock(\"process-payments\"):\n    process_pending_payments()\n</code></pre>"},{"location":"recipes/#caching-database-queries","title":"Caching Database Queries","text":"<p>Cache expensive queries with automatic invalidation:</p> <pre><code>from django.core.cache import cache\nfrom django.db.models.signals import post_save, post_delete\nfrom functools import wraps\n\ndef cached_query(timeout: int = 300):\n    \"\"\"Decorator to cache query results.\"\"\"\n    def decorator(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            # Build cache key from function name and arguments\n            key = f\"query:{func.__name__}:{hash((args, tuple(sorted(kwargs.items()))))}\"\n            result = cache.get(key)\n            if result is None:\n                result = func(*args, **kwargs)\n                cache.set(key, result, timeout=timeout)\n            return result\n        return wrapper\n    return decorator\n\n@cached_query(timeout=600)\ndef get_active_products(category_id: int):\n    return list(Product.objects.filter(\n        category_id=category_id,\n        is_active=True,\n    ).values(\"id\", \"name\", \"price\"))\n\n# Invalidate on model changes\ndef invalidate_product_cache(sender, instance, **kwargs):\n    cache.delete_pattern(\"query:get_active_products:*\")\n\npost_save.connect(invalidate_product_cache, sender=Product)\npost_delete.connect(invalidate_product_cache, sender=Product)\n</code></pre>"},{"location":"recipes/#development-and-testing-without-a-server","title":"Development and Testing Without a Server","text":"<p>Recommendation: Use a real container</p> <p>We recommend using a Valkey or Redis container even for development/testing. They're lightweight (~10MB memory) and give you accurate behavior:</p> <pre><code>docker run -d --name valkey -p 6379:6379 valkey/valkey:8\n</code></pre>"},{"location":"recipes/#using-fakeredis","title":"Using fakeredis","text":"<p>For situations where a container isn't practical, fakeredis provides an in-memory fake that implements most Redis commands.</p> <p>Configure via connection pool class:</p> <pre><code># settings.py (development/testing)\nCACHES = {\n    \"default\": {\n        \"BACKEND\": \"django_cachex.cache.RedisCache\",\n        \"LOCATION\": \"redis://localhost:6379/0\",\n        \"OPTIONS\": {\n            \"pool_class\": \"fakeredis.FakeConnectionPool\",\n        },\n    }\n}\n</code></pre> <p>Or for pytest with more control:</p> <pre><code># conftest.py\nimport pytest\n\n@pytest.fixture\ndef fake_cache_settings(settings):\n    \"\"\"Configure fakeredis for tests.\"\"\"\n    settings.CACHES = {\n        \"default\": {\n            \"BACKEND\": \"django_cachex.cache.RedisCache\",\n            \"LOCATION\": \"redis://localhost:6379/0\",\n            \"OPTIONS\": {\n                \"pool_class\": \"fakeredis.FakeConnectionPool\",\n            },\n        }\n    }\n</code></pre>"},{"location":"recipes/#using-djangos-locmemcache","title":"Using Django's LocMemCache","text":"<p>For simple tests that don't need Redis-specific features:</p> <pre><code># tests/settings.py\nCACHES = {\n    \"default\": {\n        \"BACKEND\": \"django.core.cache.backends.locmem.LocMemCache\",\n    }\n}\n</code></pre> <p>Limitations</p> <p><code>LocMemCache</code> doesn't support extended operations (lists, sets, hashes, sorted sets), pipelines, or distributed locking. Use fakeredis or a real server for those.</p>"},{"location":"getting-started/installation/","title":"Installation","text":""},{"location":"getting-started/installation/#requirements","title":"Requirements","text":"<ul> <li>Python 3.12+</li> <li>Django 5.2+</li> <li>redis-py 6+</li> <li>Redis server 6+</li> </ul>"},{"location":"getting-started/installation/#install-with-pip","title":"Install with pip","text":"<pre><code>pip install django-cachex-ng\n</code></pre>"},{"location":"getting-started/installation/#install-with-hiredis-recommended","title":"Install with hiredis (recommended)","text":"<p>For better performance, install with the hiredis parser:</p> <pre><code>pip install django-cachex-ng[hiredis]\n</code></pre> <p>The hiredis package provides a C-based parser that can significantly improve performance when parsing Redis replies.</p>"},{"location":"getting-started/installation/#verify-installation","title":"Verify Installation","text":"<pre><code>&gt;&gt;&gt; import django_cachex\n&gt;&gt;&gt; django_cachex.__version__\n'6.0.0'\n</code></pre>"},{"location":"getting-started/quickstart/","title":"Quick Start","text":""},{"location":"getting-started/quickstart/#configure-as-cache-backend","title":"Configure as Cache Backend","text":"<p>To start using django-cachex-ng, configure your Django cache settings:</p> <pre><code>CACHES = {\n    \"default\": {\n        \"BACKEND\": \"django_cachex.cache.RedisCache\",\n        \"LOCATION\": \"redis://127.0.0.1:6379/1\",\n        \"OPTIONS\": {\n            \"CLIENT_CLASS\": \"django_cachex.client.DefaultClient\",\n        }\n    }\n}\n</code></pre>"},{"location":"getting-started/quickstart/#connection-url-formats","title":"Connection URL Formats","text":"<p>django-cachex uses the redis-py native URL notation for connection strings:</p> <ul> <li><code>redis://[[username]:[password]]@localhost:6379/0</code> - TCP connection</li> <li><code>rediss://[[username]:[password]]@localhost:6379/0</code> - SSL/TLS connection</li> <li><code>unix://[[username]:[password]]@/path/to/socket.sock?db=0</code> - Unix socket</li> </ul>"},{"location":"getting-started/quickstart/#database-selection","title":"Database Selection","text":"<p>There are two ways to specify the database number:</p> <ol> <li>Query string: <code>redis://localhost?db=0</code></li> <li>Path (for <code>redis://</code> scheme): <code>redis://localhost/0</code></li> </ol>"},{"location":"getting-started/quickstart/#configure-as-session-backend","title":"Configure as Session Backend","text":"<p>Django can use any cache backend as session storage:</p> <pre><code>SESSION_ENGINE = \"django.contrib.sessions.backends.cache\"\nSESSION_CACHE_ALIAS = \"default\"\n</code></pre>"},{"location":"getting-started/quickstart/#basic-usage","title":"Basic Usage","text":"<pre><code>from django.core.cache import cache\n\n# Set a value\ncache.set(\"key\", \"value\", timeout=300)\n\n# Get a value\nvalue = cache.get(\"key\")\n\n# Delete a key\ncache.delete(\"key\")\n\n# Set multiple values\ncache.set_many({\"key1\": \"value1\", \"key2\": \"value2\"})\n\n# Get multiple values\nvalues = cache.get_many([\"key1\", \"key2\"])\n</code></pre>"},{"location":"getting-started/quickstart/#raw-redis-access","title":"Raw Redis Access","text":"<p>For advanced Redis features not exposed by Django's cache interface:</p> <pre><code>from django_cachex import get_redis_connection\n\nconn = get_redis_connection(\"default\")\nconn.set(\"raw_key\", \"raw_value\")\n</code></pre>"},{"location":"getting-started/quickstart/#testing","title":"Testing","text":"<p>To flush all cache data after tests:</p> <pre><code>from django_cachex import get_redis_connection\n\ndef tearDown(self):\n    get_redis_connection(\"default\").flushall()\n</code></pre>"},{"location":"reference/api/","title":"API Reference","text":""},{"location":"reference/api/#cache-methods","title":"Cache Methods","text":""},{"location":"reference/api/#standard-django-cache-methods","title":"Standard Django Cache Methods","text":"<p>All standard Django cache methods are supported:</p> Method Description <code>get(key, default=None)</code> Get a value <code>set(key, value, timeout=DEFAULT)</code> Set a value <code>delete(key)</code> Delete a key <code>get_many(keys)</code> Get multiple values <code>set_many(mapping, timeout=DEFAULT)</code> Set multiple values <code>delete_many(keys)</code> Delete multiple keys <code>clear()</code> Clear the cache <code>has_key(key)</code> Check if key exists <code>incr(key, delta=1)</code> Increment a value <code>decr(key, delta=1)</code> Decrement a value <code>close()</code> Close connections"},{"location":"reference/api/#extended-methods","title":"Extended Methods","text":"<p>django-cachex adds these Redis-specific methods:</p> Method Description <code>ttl(key)</code> Get TTL in seconds <code>pttl(key)</code> Get TTL in milliseconds <code>expire(key, timeout)</code> Set expiration in seconds <code>pexpire(key, timeout)</code> Set expiration in milliseconds <code>expire_at(key, when)</code> Set expiration at datetime <code>pexpire_at(key, when)</code> Set expiration at datetime (ms precision) <code>persist(key)</code> Remove expiration <code>lock(key, ...)</code> Get a distributed lock <code>keys(pattern)</code> Get keys matching pattern <code>iter_keys(pattern)</code> Iterate keys matching pattern <code>delete_pattern(pattern)</code> Delete keys matching pattern"},{"location":"reference/api/#hash-methods","title":"Hash Methods","text":"<p>Redis hash operations for field-value data structures:</p> Method Description <code>hset(key, field, value)</code> Set a hash field value <code>hdel(key, *fields)</code> Delete hash field(s) <code>hexists(key, field)</code> Check if hash field exists <code>hget(key, field)</code> Get a hash field value <code>hgetall(key)</code> Get all fields and values in a hash <code>hincrby(key, field, amount=1)</code> Increment hash field by integer <code>hincrbyfloat(key, field, amount=1.0)</code> Increment hash field by float <code>hlen(key)</code> Get number of fields in hash <code>hmget(key, *fields)</code> Get multiple hash field values <code>hmset(key, mapping)</code> Set multiple hash fields <code>hsetnx(key, field, value)</code> Set hash field only if it doesn't exist <code>hvals(key)</code> Get all values in a hash"},{"location":"reference/api/#sorted-set-methods","title":"Sorted Set Methods","text":"<p>Redis sorted set operations for scored, ordered collections:</p> Method Description <code>zadd(key, *args, **kwargs)</code> Add member(s) with scores <code>zcard(key)</code> Get number of members <code>zcount(key, min, max)</code> Count members with scores in range <code>zincrby(key, amount, member)</code> Increment member's score <code>zrange(key, start, end, ...)</code> Get members by index range <code>zrangebyscore(key, min, max, ...)</code> Get members by score range <code>zrank(key, member)</code> Get member's rank (ascending) <code>zrevrank(key, member)</code> Get member's rank (descending) <code>zrem(key, *members)</code> Remove member(s) <code>zremrangebyrank(key, start, end)</code> Remove members by rank range <code>zscore(key, member)</code> Get member's score <code>zmscore(key, *members)</code> Get multiple members' scores"},{"location":"reference/api/#list-methods","title":"List Methods","text":"<p>Redis list operations for ordered, indexable collections:</p> Method Description <code>llen(key)</code> Get list length <code>lpush(key, *values)</code> Prepend value(s) to list <code>rpush(key, *values)</code> Append value(s) to list <code>lpop(key)</code> Remove and return first element <code>rpop(key)</code> Remove and return last element <code>lindex(key, index)</code> Get element by index <code>lrange(key, start, end)</code> Get elements in range <code>lset(key, index, value)</code> Set element at index <code>ltrim(key, start, end)</code> Trim list to range <code>lpos(key, element, ...)</code> Find element position in list <code>lmove(src, dst, src_side, dst_side)</code> Atomically move element between lists"},{"location":"reference/api/#set-method-options","title":"Set Method Options","text":"<pre><code>cache.set(key, value, timeout=300, nx=False, xx=False)\n</code></pre> Parameter Description <code>timeout</code> Expiration in seconds (<code>None</code> = never, <code>0</code> = immediate) <code>nx</code> Only set if key doesn't exist (SETNX) <code>xx</code> Only set if key exists"},{"location":"reference/api/#helper-functions","title":"Helper Functions","text":""},{"location":"reference/api/#get_redis_connection","title":"get_redis_connection","text":"<pre><code>from django_cachex import get_redis_connection\n\nconn = get_redis_connection(alias=\"default\", write=True)\n</code></pre> Parameter Description <code>alias</code> Cache alias from settings (default: <code>\"default\"</code>) <code>write</code> Get write connection for primary (default: <code>True</code>) <p>Returns the underlying <code>redis.Redis</code> client instance.</p>"},{"location":"reference/api/#lock-interface","title":"Lock Interface","text":"<pre><code>lock = cache.lock(key, timeout=None, sleep=0.1, blocking=True, blocking_timeout=None)\n</code></pre> Parameter Description <code>key</code> Lock name <code>timeout</code> Lock auto-release timeout <code>sleep</code> Time between acquire attempts <code>blocking</code> Wait for lock if held <code>blocking_timeout</code> Max wait time for lock <p>Compatible with <code>threading.Lock</code>:</p> <pre><code># Context manager\nwith cache.lock(\"mylock\"):\n    do_work()\n\n# Manual acquire/release\nlock = cache.lock(\"mylock\")\nif lock.acquire():\n    try:\n        do_work()\n    finally:\n        lock.release()\n</code></pre>"},{"location":"reference/api/#settings-reference","title":"Settings Reference","text":""},{"location":"reference/api/#cache-options","title":"Cache OPTIONS","text":"Option Description <code>CLIENT_CLASS</code> Client implementation class <code>SERIALIZER</code> Serializer class <code>COMPRESSOR</code> Compressor class <code>PASSWORD</code> Redis password <code>SOCKET_CONNECT_TIMEOUT</code> Connection timeout <code>SOCKET_TIMEOUT</code> Read/write timeout <code>IGNORE_EXCEPTIONS</code> Ignore connection errors <code>PICKLE_VERSION</code> Pickle protocol version <code>CONNECTION_POOL_CLASS</code> Custom pool class <code>CONNECTION_POOL_KWARGS</code> Pool configuration <code>CLOSE_CONNECTION</code> Close connections on cache close <code>SENTINELS</code> Sentinel server list <code>SENTINEL_KWARGS</code> Sentinel configuration"},{"location":"reference/api/#global-settings","title":"Global Settings","text":"Setting Description <code>DJANGO_REDIS_CONNECTION_FACTORY</code> Connection factory class <code>DJANGO_REDIS_IGNORE_EXCEPTIONS</code> Global exception handling <code>DJANGO_REDIS_LOG_IGNORED_EXCEPTIONS</code> Log ignored exceptions <code>DJANGO_REDIS_LOGGER</code> Logger name for exceptions <code>DJANGO_REDIS_CLOSE_CONNECTION</code> Global close behavior <code>DJANGO_REDIS_SCAN_ITERSIZE</code> Default scan batch size"},{"location":"reference/changelog/","title":"Changelog","text":""},{"location":"reference/changelog/#600-unreleased","title":"6.0.0 (Unreleased)","text":"<p>This is the first release of django-cachex-ng, a fork of django-cachex.</p>"},{"location":"reference/changelog/#changes-from-django-cachex","title":"Changes from django-cachex","text":"<ul> <li>Minimum Python version raised to 3.12</li> <li>Minimum Django version raised to 5.2</li> <li>Minimum redis-py version raised to 6.0 (released April 2025)</li> <li>Migrated to <code>pyproject.toml</code> with hatchling build system</li> <li>Switched to UV for package management</li> <li>Modernized CI/CD with GitHub Actions</li> <li>Added MkDocs documentation with Material theme</li> <li>Package name changed to <code>django-cachex-ng</code> (import namespace remains <code>django_cachex</code>)</li> <li>Removed ShardClient and HerdClient (not commonly used, untested)</li> <li>Tests now use testcontainers instead of docker-compose</li> </ul>"},{"location":"reference/changelog/#new-features","title":"New Features","text":"<ul> <li>ClusterClient: New client for Redis Cluster deployments with server-side sharding</li> <li>Hash operations: <code>hset</code>, <code>hdel</code>, <code>hexists</code>, <code>hget</code>, <code>hgetall</code>, <code>hincrby</code>, <code>hincrbyfloat</code>, <code>hlen</code>, <code>hmget</code>, <code>hmset</code>, <code>hsetnx</code>, <code>hvals</code></li> <li>Sorted set operations: <code>zadd</code>, <code>zcard</code>, <code>zcount</code>, <code>zincrby</code>, <code>zrange</code>, <code>zrangebyscore</code>, <code>zrank</code>, <code>zrevrank</code>, <code>zrem</code>, <code>zremrangebyrank</code>, <code>zscore</code>, <code>zmscore</code></li> <li>List operations: <code>llen</code>, <code>lpush</code>, <code>rpush</code>, <code>lpop</code>, <code>rpop</code>, <code>lindex</code>, <code>lrange</code>, <code>lset</code>, <code>ltrim</code>, <code>lpos</code>, <code>lmove</code></li> </ul>"},{"location":"reference/changelog/#features","title":"Features","text":"<p>All features from django-cachex 5.x are included:</p> <ul> <li>Full-featured Redis cache backend</li> <li>Session backend support</li> <li>Pluggable clients (Default, Sentinel, Cluster)</li> <li>Pluggable serializers (Pickle, JSON, MsgPack)</li> <li>Pluggable compressors (Zlib, Gzip, LZMA, LZ4, Zstandard)</li> <li>Connection pooling</li> <li>Primary/replica replication</li> <li>Redis Sentinel support</li> <li>Distributed locks</li> <li>TTL operations</li> <li>Bulk key operations</li> </ul>"},{"location":"reference/changelog/#previous-releases","title":"Previous Releases","text":"<p>For the changelog of the original django-cachex project, see the django-cachex repository.</p>"},{"location":"user-guide/advanced/","title":"Advanced Usage","text":""},{"location":"user-guide/advanced/#pickle-version","title":"Pickle Version","text":"<p>By default, django-cachex uses <code>pickle.DEFAULT_PROTOCOL</code>. To set a specific version:</p> <pre><code>CACHES = {\n    \"default\": {\n        \"BACKEND\": \"django_cachex.cache.RedisCache\",\n        \"LOCATION\": \"redis://127.0.0.1:6379/1\",\n        \"OPTIONS\": {\n            \"PICKLE_VERSION\": -1  # Highest protocol available\n        }\n    }\n}\n</code></pre>"},{"location":"user-guide/advanced/#ttl-operations","title":"TTL Operations","text":""},{"location":"user-guide/advanced/#get-ttl","title":"Get TTL","text":"<pre><code>from django.core.cache import cache\n\ncache.set(\"foo\", \"value\", timeout=25)\ncache.ttl(\"foo\")      # Returns 25\ncache.ttl(\"missing\")  # Returns 0 (key doesn't exist)\n</code></pre> <p>Returns:</p> <ul> <li><code>0</code> - Key doesn't exist or already expired</li> <li><code>None</code> - Key exists but has no expiration</li> <li><code>int</code> - Seconds until expiration</li> </ul>"},{"location":"user-guide/advanced/#get-ttl-in-milliseconds","title":"Get TTL in Milliseconds","text":"<pre><code>cache.set(\"foo\", \"value\", timeout=25)\ncache.pttl(\"foo\")  # Returns 25000\n</code></pre>"},{"location":"user-guide/advanced/#expire-persist","title":"Expire &amp; Persist","text":""},{"location":"user-guide/advanced/#set-expiration","title":"Set Expiration","text":"<pre><code>cache.set(\"foo\", \"bar\", timeout=22)\ncache.expire(\"foo\", timeout=5)\ncache.ttl(\"foo\")  # Returns 5\n</code></pre>"},{"location":"user-guide/advanced/#set-expiration-in-milliseconds","title":"Set Expiration in Milliseconds","text":"<pre><code>cache.set(\"foo\", \"bar\", timeout=22)\ncache.pexpire(\"foo\", timeout=5500)\ncache.pttl(\"foo\")  # Returns 5500\n</code></pre>"},{"location":"user-guide/advanced/#expire-at-specific-time","title":"Expire at Specific Time","text":"<pre><code>from datetime import datetime, timedelta\n\ncache.set(\"foo\", \"bar\", timeout=22)\ncache.expire_at(\"foo\", datetime.now() + timedelta(hours=1))\ncache.ttl(\"foo\")  # Returns ~3600\n</code></pre>"},{"location":"user-guide/advanced/#expire-at-specific-time-milliseconds-precision","title":"Expire at Specific Time (milliseconds precision)","text":"<pre><code>cache.set(\"foo\", \"bar\", timeout=22)\ncache.pexpire_at(\"foo\", datetime.now() + timedelta(milliseconds=900, hours=1))\ncache.pttl(\"foo\")  # Returns ~3600900\n</code></pre>"},{"location":"user-guide/advanced/#remove-expiration","title":"Remove Expiration","text":"<pre><code>cache.set(\"foo\", \"bar\", timeout=22)\ncache.persist(\"foo\")\ncache.ttl(\"foo\")  # Returns None (no expiration)\n</code></pre>"},{"location":"user-guide/advanced/#locks","title":"Locks","text":"<p>Redis distributed locks with the same interface as <code>threading.Lock</code>:</p> <pre><code>from django.core.cache import cache\n\nwith cache.lock(\"somekey\"):\n    do_some_thing()\n</code></pre>"},{"location":"user-guide/advanced/#bulk-operations","title":"Bulk Operations","text":""},{"location":"user-guide/advanced/#search-keys","title":"Search Keys","text":"<pre><code>from django.core.cache import cache\n\n# Get all matching keys (not recommended for large datasets)\ncache.keys(\"foo_*\")  # Returns [\"foo_1\", \"foo_2\"]\n</code></pre>"},{"location":"user-guide/advanced/#iterate-keys-recommended","title":"Iterate Keys (Recommended)","text":"<p>For large datasets, use server-side cursors:</p> <pre><code># Returns a generator\nfor key in cache.iter_keys(\"foo_*\"):\n    print(key)\n</code></pre>"},{"location":"user-guide/advanced/#delete-by-pattern","title":"Delete by Pattern","text":"<pre><code>cache.delete_pattern(\"foo_*\")\n</code></pre> <p>For better performance with many keys:</p> <pre><code>cache.delete_pattern(\"foo_*\", itersize=100_000)\n</code></pre> <p>Or set globally:</p> <pre><code>DJANGO_REDIS_SCAN_ITERSIZE = 100_000\n</code></pre>"},{"location":"user-guide/advanced/#atomic-operations","title":"Atomic Operations","text":""},{"location":"user-guide/advanced/#setnx-set-if-not-exists","title":"SETNX (Set if Not Exists)","text":"<pre><code>cache.set(\"key\", \"value1\", nx=True)  # Returns True\ncache.set(\"key\", \"value2\", nx=True)  # Returns False\ncache.get(\"key\")  # Returns \"value1\"\n</code></pre>"},{"location":"user-guide/advanced/#incrementdecrement","title":"Increment/Decrement","text":"<pre><code>cache.set(\"counter\", 0)\ncache.incr(\"counter\")  # Returns 1\ncache.incr(\"counter\", delta=5)  # Returns 6\ncache.decr(\"counter\")  # Returns 5\n</code></pre>"},{"location":"user-guide/advanced/#redis-data-structures","title":"Redis Data Structures","text":"<p>django-cachex provides direct access to Redis data structures through the cache interface.</p>"},{"location":"user-guide/advanced/#hashes","title":"Hashes","text":"<p>Hashes are maps of field-value pairs, useful for storing objects:</p> <pre><code>from django.core.cache import cache\n\n# Set a single field\ncache.hset(\"user:1\", \"name\", \"Alice\")\n\n# Set multiple fields at once\ncache.hmset(\"user:1\", {\"email\": \"alice@example.com\", \"age\": 30})\n\n# Get a single field\nname = cache.hget(\"user:1\", \"name\")  # \"Alice\"\n\n# Get multiple fields\nvalues = cache.hmget(\"user:1\", \"name\", \"email\")  # [\"Alice\", \"alice@example.com\"]\n\n# Get all fields and values\nuser = cache.hgetall(\"user:1\")  # {\"name\": \"Alice\", \"email\": \"...\", \"age\": 30}\n\n# Increment a numeric field\ncache.hincrby(\"user:1\", \"age\", 1)  # 31\ncache.hincrbyfloat(\"user:1\", \"score\", 0.5)  # For floating point\n\n# Check if field exists\ncache.hexists(\"user:1\", \"name\")  # True\n\n# Delete fields\ncache.hdel(\"user:1\", \"age\")\n\n# Get count of fields\ncache.hlen(\"user:1\")  # 2\n\n# Get all values\ncache.hvals(\"user:1\")  # [\"Alice\", \"alice@example.com\"]\n</code></pre>"},{"location":"user-guide/advanced/#sorted-sets","title":"Sorted Sets","text":"<p>Sorted sets store unique members with scores, automatically sorted by score:</p> <pre><code>from django.core.cache import cache\n\n# Add members with scores\ncache.zadd(\"leaderboard\", {\"alice\": 100, \"bob\": 85, \"charlie\": 92})\n\n# Get rank (0-indexed, ascending by score)\ncache.zrank(\"leaderboard\", \"alice\")  # 2 (highest score = last)\ncache.zrevrank(\"leaderboard\", \"alice\")  # 0 (highest score = first)\n\n# Get score\ncache.zscore(\"leaderboard\", \"bob\")  # 85.0\n\n# Get multiple scores\ncache.zmscore(\"leaderboard\", \"alice\", \"bob\")  # [100.0, 85.0]\n\n# Increment score\ncache.zincrby(\"leaderboard\", 10, \"bob\")  # 95.0\n\n# Get range by rank (ascending)\ncache.zrange(\"leaderboard\", 0, -1)  # All members sorted by score\n\n# Get range by rank with scores\ncache.zrange(\"leaderboard\", 0, -1, withscores=True)\n\n# Get range by score\ncache.zrangebyscore(\"leaderboard\", 80, 100)\n\n# Count members in score range\ncache.zcount(\"leaderboard\", 80, 100)  # 3\n\n# Remove members\ncache.zrem(\"leaderboard\", \"charlie\")\n\n# Remove by rank range\ncache.zremrangebyrank(\"leaderboard\", 0, 1)  # Remove lowest 2\n\n# Get total count\ncache.zcard(\"leaderboard\")\n</code></pre>"},{"location":"user-guide/advanced/#lists","title":"Lists","text":"<p>Lists are ordered collections of elements:</p> <pre><code>from django.core.cache import cache\n\n# Push elements\ncache.lpush(\"queue\", \"first\")  # Prepend (left)\ncache.rpush(\"queue\", \"last\")   # Append (right)\n\n# Pop elements\ncache.lpop(\"queue\")  # Remove and return first\ncache.rpop(\"queue\")  # Remove and return last\n\n# Get element by index\ncache.lindex(\"queue\", 0)  # First element\n\n# Get range of elements\ncache.lrange(\"queue\", 0, -1)  # All elements\n\n# Set element at index\ncache.lset(\"queue\", 0, \"new_first\")\n\n# Trim to range\ncache.ltrim(\"queue\", 0, 99)  # Keep first 100 elements\n\n# Get length\ncache.llen(\"queue\")\n\n# Find element position (Redis 6.0.6+)\ncache.lpos(\"queue\", \"target\")  # Returns index or None\n\n# Move element between lists atomically (Redis 6.2+)\ncache.lmove(\"source\", \"dest\", \"LEFT\", \"RIGHT\")  # LPOP source, RPUSH dest\n</code></pre>"},{"location":"user-guide/advanced/#raw-client-access","title":"Raw Client Access","text":"<p>Access the underlying redis-py client:</p> <pre><code>from django_cachex import get_redis_connection\n\nconn = get_redis_connection(\"default\")\nconn.set(\"raw_key\", \"raw_value\")\nconn.hset(\"hash_key\", \"field\", \"value\")\n</code></pre> <p>Warning</p> <p>Not all pluggable clients support this feature.</p>"},{"location":"user-guide/clients/","title":"Pluggable Clients","text":"<p>django-cachex provides several pluggable client implementations for different use cases.</p>"},{"location":"user-guide/clients/#default-client","title":"Default Client","text":"<p>The default client supports primary/replica replication:</p> <pre><code>CACHES = {\n    \"default\": {\n        \"BACKEND\": \"django_cachex.cache.RedisCache\",\n        \"LOCATION\": [\n            \"redis://127.0.0.1:6379/1\",  # Primary\n            \"redis://127.0.0.1:6378/1\",  # Replica\n        ],\n        \"OPTIONS\": {\n            \"CLIENT_CLASS\": \"django_cachex.client.DefaultClient\",\n        }\n    }\n}\n</code></pre> <p>Warning</p> <p>Replication setup is not heavily tested in production environments.</p>"},{"location":"user-guide/clients/#sentinel-client","title":"Sentinel Client","text":"<p>For Redis Sentinel high availability setups. See Sentinel for detailed configuration.</p> <pre><code>CACHES = {\n    \"default\": {\n        \"BACKEND\": \"django_cachex.cache.RedisCache\",\n        \"LOCATION\": \"redis://service_name/db\",\n        \"OPTIONS\": {\n            \"CLIENT_CLASS\": \"django_cachex.client.SentinelClient\",\n            \"SENTINELS\": [\n                (\"sentinel-1\", 26379),\n                (\"sentinel-2\", 26379),\n            ],\n        },\n    },\n}\n</code></pre>"},{"location":"user-guide/clients/#cluster-client","title":"Cluster Client","text":"<p>For Redis Cluster deployments with server-side sharding across multiple nodes. See Cluster for detailed configuration and slot handling.</p> <pre><code>CACHES = {\n    \"default\": {\n        \"BACKEND\": \"django_cachex.cache.RedisCache\",\n        \"LOCATION\": \"redis://127.0.0.1:7000\",  # Any cluster node\n        \"OPTIONS\": {\n            \"CLIENT_CLASS\": \"django_cachex.client.ClusterClient\",\n            \"CONNECTION_FACTORY\": \"django_cachex.pool.ClusterConnectionFactory\",\n        }\n    }\n}\n</code></pre> <p>Cluster Behavior</p> <ul> <li>Django cache interface methods (<code>get_many</code>, <code>set_many</code>, <code>delete_many</code>, <code>keys</code>, <code>clear</code>, etc.) are cluster-aware and handle cross-slot keys automatically</li> <li>Direct Redis method wrappers (sets, lists, hashes) pass through to Redis - use hash tags for multi-key operations</li> <li>See the Cluster documentation for details on slot handling and hash tags</li> </ul>"},{"location":"user-guide/cluster/","title":"Redis Cluster","text":"<p>django-cachex includes built-in support for Redis Cluster with server-side sharding across multiple nodes.</p>"},{"location":"user-guide/cluster/#basic-setup","title":"Basic Setup","text":"<p>Use <code>RedisClusterCacheClient</code> (or <code>ValkeyClusterCacheClient</code> for Valkey):</p> <pre><code>CACHES = {\n    \"default\": {\n        \"BACKEND\": \"django_cachex.client.RedisClusterCacheClient\",\n        \"LOCATION\": \"redis://127.0.0.1:7000\",  # Any cluster node\n    }\n}\n</code></pre>"},{"location":"user-guide/cluster/#full-configuration-example","title":"Full Configuration Example","text":"<pre><code>CACHES = {\n    \"default\": {\n        \"BACKEND\": \"django_cachex.client.RedisClusterCacheClient\",\n        \"LOCATION\": \"redis://127.0.0.1:7000\",\n        \"OPTIONS\": {\n            # Connection options (passed to RedisCluster)\n            \"socket_timeout\": 5,\n            \"socket_connect_timeout\": 3,\n        }\n    }\n}\n</code></pre> <p>For Valkey Cluster:</p> <pre><code>CACHES = {\n    \"default\": {\n        \"BACKEND\": \"django_cachex.client.ValkeyClusterCacheClient\",\n        \"LOCATION\": \"redis://127.0.0.1:7000\",\n    }\n}\n</code></pre>"},{"location":"user-guide/cluster/#understanding-cluster-slot-handling","title":"Understanding Cluster Slot Handling","text":"<p>Redis Cluster distributes keys across 16384 hash slots. When using multi-key operations, Redis requires all keys to be on the same slot for atomicity. django-cachex handles this automatically for standard Django cache operations, but you need to understand the distinction between two types of methods:</p>"},{"location":"user-guide/cluster/#django-cache-interface-methods-automatic-handling","title":"Django Cache Interface Methods (Automatic Handling)","text":"<p>These methods are part of the standard Django cache interface and are cluster-aware. They automatically handle cross-slot operations by grouping keys appropriately or querying all nodes:</p> Method Cluster Behavior <code>get_many()</code> Automatically splits keys by slot using <code>mget_nonatomic</code> <code>set_many()</code> Automatically splits keys by slot using <code>mset_nonatomic</code> <code>delete_many()</code> Groups keys by slot and performs multiple DEL operations <code>keys()</code> Queries all primary nodes with <code>target_nodes=PRIMARIES</code> <code>iter_keys()</code> Scans all primary nodes with <code>target_nodes=PRIMARIES</code> <code>delete_pattern()</code> Scans all primaries and groups deletions by slot <code>clear()</code> Flushes all primary nodes in the cluster <p>Non-Atomic Operations</p> <p>Operations like <code>get_many</code> and <code>set_many</code> use redis-py's <code>_nonatomic</code> variants which split keys across slots. This means these operations are not atomic across the entire key set, but each slot group is processed atomically.</p>"},{"location":"user-guide/cluster/#direct-redis-method-wrappers-pass-through","title":"Direct Redis Method Wrappers (Pass-Through)","text":"<p>Methods from the Redis data structure mixins (sets, lists, hashes, sorted sets) are direct wrappers around Redis commands. They pass through to Redis without special cluster handling:</p> Category Methods Sets <code>sadd</code>, <code>srem</code>, <code>smembers</code>, <code>sismember</code>, <code>scard</code>, <code>sdiff</code>, <code>sinter</code>, <code>sunion</code>, <code>smove</code>, etc. Lists <code>lpush</code>, <code>rpush</code>, <code>lpop</code>, <code>rpop</code>, <code>lrange</code>, <code>lindex</code>, <code>llen</code>, <code>lmove</code>, etc. Hashes <code>hset</code>, <code>hget</code>, <code>hmset</code>, <code>hmget</code>, <code>hdel</code>, <code>hgetall</code>, <code>hkeys</code>, <code>hvals</code>, etc. Sorted Sets <code>zadd</code>, <code>zrem</code>, <code>zrange</code>, <code>zscore</code>, <code>zcard</code>, <code>zrangebyscore</code>, etc. <p>Multi-Key Commands Require Same Slot</p> <p>Multi-key commands like <code>sdiff</code>, <code>sinter</code>, <code>sunion</code>, <code>smove</code>, and <code>lmove</code> require all keys to be on the same slot. Use hash tags to ensure this (see below).</p>"},{"location":"user-guide/cluster/#hash-tags-for-slot-co-location","title":"Hash Tags for Slot Co-location","text":"<p>Redis Cluster uses hash tags to force keys to the same slot. A hash tag is the substring between the first <code>{</code> and the following <code>}</code> in a key:</p> <pre><code># These keys will be on the SAME slot (hash tag is \"user:123\")\ncache.sadd(\"{user:123}:followers\", \"alice\", \"bob\")\ncache.sadd(\"{user:123}:following\", \"charlie\")\n\n# Now multi-key operations work\nfollowers_not_following = cache.sdiff(\n    \"{user:123}:followers\",\n    \"{user:123}:following\"\n)\n</code></pre>"},{"location":"user-guide/cluster/#when-to-use-hash-tags","title":"When to Use Hash Tags","text":"<p>Use hash tags when you need to:</p> <ol> <li>Perform set operations across keys: <code>sdiff</code>, <code>sinter</code>, <code>sunion</code>, <code>smove</code></li> <li>Move items between lists: <code>lmove</code></li> <li>Use transactions (MULTI/EXEC) across multiple keys</li> <li>Ensure atomicity for related keys</li> </ol> <pre><code># Shopping cart example - all cart data on same slot\ncart_key = \"{cart:user42}:items\"\ncart_meta = \"{cart:user42}:metadata\"\n\ncache.sadd(cart_key, \"item1\", \"item2\")\ncache.hset(cart_meta, \"total\", \"29.99\")\n</code></pre>"},{"location":"user-guide/cluster/#hash-tag-best-practices","title":"Hash Tag Best Practices","text":"<p>Keep Hash Tags Consistent</p> <p>Use a logical grouping for your hash tags that matches your access patterns.</p> <pre><code># Good: Group by user\n\"{user:123}:profile\"\n\"{user:123}:settings\"\n\"{user:123}:sessions\"\n\n# Good: Group by entity\n\"{order:456}:items\"\n\"{order:456}:status\"\n\n# Avoid: Overly broad tags that create hot spots\n\"{app}:user:123\"  # All users on one slot!\n</code></pre>"},{"location":"user-guide/cluster/#example-set-operations-in-cluster","title":"Example: Set Operations in Cluster","text":"<pre><code>from django.core.cache import cache\n\n# Without hash tags - keys may be on different slots\n# These individual operations work fine:\ncache.sadd(\"set1\", \"a\", \"b\", \"c\")\ncache.sadd(\"set2\", \"b\", \"c\", \"d\")\n\n# But this will FAIL with CROSSSLOT error:\n# cache.sinter(\"set1\", \"set2\")  # Error!\n\n# With hash tags - keys are guaranteed on same slot:\ncache.sadd(\"{mysets}:set1\", \"a\", \"b\", \"c\")\ncache.sadd(\"{mysets}:set2\", \"b\", \"c\", \"d\")\n\n# Now this works:\ncommon = cache.sinter(\"{mysets}:set1\", \"{mysets}:set2\")\n# Returns: {\"b\", \"c\"}\n</code></pre>"},{"location":"user-guide/cluster/#example-list-operations-in-cluster","title":"Example: List Operations in Cluster","text":"<pre><code>from django.core.cache import cache\n\n# Moving items between lists requires same slot\ncache.rpush(\"{queue}:pending\", \"task1\", \"task2\", \"task3\")\ncache.rpush(\"{queue}:processing\", \"task0\")\n\n# Move task from pending to processing\ntask = cache.lmove(\"{queue}:pending\", \"{queue}:processing\", \"LEFT\", \"RIGHT\")\n# Returns: \"task1\"\n</code></pre>"},{"location":"user-guide/cluster/#design-philosophy","title":"Design Philosophy","text":"<p>The cluster client follows these principles:</p> <ol> <li> <p>Django cache interface should \"just work\": Methods like <code>get_many()</code>, <code>set_many()</code>, <code>clear()</code>, etc. should work without users needing to think about cluster topology or slot distribution.</p> </li> <li> <p>Redis method wrappers stay true to Redis: Direct Redis commands (set operations, list operations, etc.) behave exactly as they would with a regular Redis client. This means no hidden magic, but also no hidden safety nets.</p> </li> <li> <p>Explicit over implicit for advanced operations: When using Redis-specific features in cluster mode, you're expected to understand cluster constraints and use hash tags appropriately.</p> </li> </ol> <p>This design ensures that:</p> <ul> <li>Simple Django caching works seamlessly with clusters</li> <li>Power users get full Redis functionality without unexpected behavior</li> <li>There's no confusion about which methods handle slots and which don't</li> </ul>"},{"location":"user-guide/compression/","title":"Compression","text":"<p>django-cachex supports several compression backends to reduce memory usage.</p>"},{"location":"user-guide/compression/#zlib-compression","title":"Zlib Compression","text":"<pre><code>CACHES = {\n    \"default\": {\n        \"BACKEND\": \"django_cachex.cache.RedisCache\",\n        \"LOCATION\": \"redis://127.0.0.1:6379/1\",\n        \"OPTIONS\": {\n            \"COMPRESSOR\": \"django_cachex.compressors.zlib.ZlibCompressor\",\n        }\n    }\n}\n</code></pre>"},{"location":"user-guide/compression/#gzip-compression","title":"Gzip Compression","text":"<pre><code>CACHES = {\n    \"default\": {\n        \"BACKEND\": \"django_cachex.cache.RedisCache\",\n        \"LOCATION\": \"redis://127.0.0.1:6379/1\",\n        \"OPTIONS\": {\n            \"COMPRESSOR\": \"django_cachex.compressors.gzip.GzipCompressor\",\n        }\n    }\n}\n</code></pre>"},{"location":"user-guide/compression/#lzma-compression","title":"LZMA Compression","text":"<pre><code>CACHES = {\n    \"default\": {\n        \"BACKEND\": \"django_cachex.cache.RedisCache\",\n        \"LOCATION\": \"redis://127.0.0.1:6379/1\",\n        \"OPTIONS\": {\n            \"COMPRESSOR\": \"django_cachex.compressors.lzma.LzmaCompressor\",\n        }\n    }\n}\n</code></pre>"},{"location":"user-guide/compression/#lz4-compression","title":"LZ4 Compression","text":"<p>Requires the <code>lz4</code> library:</p> <pre><code>pip install lz4\n</code></pre> <pre><code>CACHES = {\n    \"default\": {\n        \"BACKEND\": \"django_cachex.cache.RedisCache\",\n        \"LOCATION\": \"redis://127.0.0.1:6379/1\",\n        \"OPTIONS\": {\n            \"COMPRESSOR\": \"django_cachex.compressors.lz4.Lz4Compressor\",\n        }\n    }\n}\n</code></pre>"},{"location":"user-guide/compression/#zstandard-zstd-compression","title":"Zstandard (zstd) Compression","text":"<p>On Python 3.14+, zstd compression uses the built-in <code>compression.zstd</code> module. On older Python versions, it falls back to <code>backports-zstd</code>.</p> <pre><code>CACHES = {\n    \"default\": {\n        \"BACKEND\": \"django_cachex.cache.RedisCache\",\n        \"LOCATION\": \"redis://127.0.0.1:6379/1\",\n        \"OPTIONS\": {\n            \"COMPRESSOR\": \"django_cachex.compressors.zstd.ZStdCompressor\",\n        }\n    }\n}\n</code></pre>"},{"location":"user-guide/compression/#compressor-fallback-migration-support","title":"Compressor Fallback (Migration Support)","text":"<p>When migrating from one compressor to another, you can specify a list of compressors. The first compressor is used for writing new data, while all compressors are tried in order when reading until one succeeds.</p> <p>This allows safe migration between compression formats without data loss:</p> <pre><code>CACHES = {\n    \"default\": {\n        \"BACKEND\": \"django_cachex.cache.RedisCache\",\n        \"LOCATION\": \"redis://127.0.0.1:6379/1\",\n        \"OPTIONS\": {\n            # First compressor used for writing, all tried for reading\n            \"COMPRESSOR\": [\n                \"django_cachex.compressors.zstd.ZStdCompressor\",  # New format\n                \"django_cachex.compressors.gzip.GzipCompressor\",  # Old format\n            ],\n        }\n    }\n}\n</code></pre>"},{"location":"user-guide/compression/#migration-example","title":"Migration Example","text":"<ol> <li> <p>Before migration - using gzip:    <pre><code>\"COMPRESSOR\": \"django_cachex.compressors.gzip.GzipCompressor\"\n</code></pre></p> </li> <li> <p>During migration - write zstd, read both:    <pre><code>\"COMPRESSOR\": [\n    \"django_cachex.compressors.zstd.ZStdCompressor\",\n    \"django_cachex.compressors.gzip.GzipCompressor\",\n]\n</code></pre></p> </li> <li> <p>After migration - all data refreshed with zstd:    <pre><code>\"COMPRESSOR\": \"django_cachex.compressors.zstd.ZStdCompressor\"\n</code></pre></p> </li> </ol>"},{"location":"user-guide/compression/#how-it-works","title":"How It Works","text":"<p>When decompressing, each compressor is tried in order. If decompression fails, the next compressor is tried. This continues until one succeeds or all fail. If all compressors fail, the raw value is returned (allowing uncompressed data to pass through).</p>"},{"location":"user-guide/compression/#compression-comparison","title":"Compression Comparison","text":"Compressor Speed Ratio Dependencies Zlib Medium Good Built-in Gzip Medium Good Built-in LZMA Slow Best Built-in LZ4 Fast Moderate <code>lz4</code> Zstandard Fast Good <code>pyzstd</code>"},{"location":"user-guide/configuration/","title":"Configuration Reference","text":"<p>Complete reference for all django-cachex configuration options.</p>"},{"location":"user-guide/configuration/#basic-configuration","title":"Basic Configuration","text":"<pre><code>CACHES = {\n    \"default\": {\n        \"BACKEND\": \"django_cachex.cache.RedisCache\",  # or ValkeyCache\n        \"LOCATION\": \"redis://127.0.0.1:6379/1\",\n        \"TIMEOUT\": 300,              # Default timeout in seconds\n        \"KEY_PREFIX\": \"myapp\",       # Prefix for all keys\n        \"VERSION\": 1,                # Key version number\n        \"OPTIONS\": {\n            # See options below\n        }\n    }\n}\n</code></pre>"},{"location":"user-guide/configuration/#backend-classes","title":"Backend Classes","text":"Backend Description <code>django_cachex.cache.RedisCache</code> Standard Redis (redis-py) <code>django_cachex.cache.ValkeyCache</code> Standard Valkey (valkey-py) <code>django_cachex.cache.RedisSentinelCache</code> Redis with Sentinel <code>django_cachex.cache.ValkeySentinelCache</code> Valkey with Sentinel <code>django_cachex.cache.RedisClusterCache</code> Redis Cluster <code>django_cachex.cache.ValkeyClusterCache</code> Valkey Cluster"},{"location":"user-guide/configuration/#location","title":"LOCATION","text":"<p>Server URL(s). Supports multiple formats:</p> <pre><code># Single server\n\"LOCATION\": \"redis://127.0.0.1:6379/1\"\n\n# With authentication\n\"LOCATION\": \"redis://user:password@127.0.0.1:6379/1\"\n\n# SSL/TLS\n\"LOCATION\": \"rediss://127.0.0.1:6379/1\"\n\n# Unix socket\n\"LOCATION\": \"unix:///path/to/socket?db=1\"\n\n# Multiple servers (read replicas)\n\"LOCATION\": [\n    \"redis://127.0.0.1:6379/1\",  # Primary (writes)\n    \"redis://127.0.0.1:6380/1\",  # Replica (reads)\n]\n\n# Or comma/semicolon separated\n\"LOCATION\": \"redis://127.0.0.1:6379/1,redis://127.0.0.1:6380/1\"\n</code></pre>"},{"location":"user-guide/configuration/#options-reference","title":"OPTIONS Reference","text":""},{"location":"user-guide/configuration/#serialization","title":"Serialization","text":"<pre><code>\"OPTIONS\": {\n    # Single serializer (string path, class, or instance)\n    \"serializer\": \"django_cachex.serializers.pickle.PickleSerializer\",\n\n    # Or with fallback for migration\n    \"serializer\": [\n        \"django_cachex.serializers.msgpack.MsgPackSerializer\",  # Write\n        \"django_cachex.serializers.pickle.PickleSerializer\",    # Fallback read\n    ],\n}\n</code></pre> <p>Available serializers:</p> Serializer Description <code>django_cachex.serializers.pickle.PickleSerializer</code> Python pickle (default) <code>django_cachex.serializers.json.JSONSerializer</code> JSON <code>django_cachex.serializers.msgpack.MsgPackSerializer</code> MessagePack (requires msgpack)"},{"location":"user-guide/configuration/#compression","title":"Compression","text":"<pre><code>\"OPTIONS\": {\n    # Single compressor\n    \"compressor\": \"django_cachex.compressors.zstd.ZstdCompressor\",\n\n    # Or with fallback for migration\n    \"compressor\": [\n        \"django_cachex.compressors.zstd.ZstdCompressor\",  # Write\n        \"django_cachex.compressors.zlib.ZlibCompressor\",  # Fallback read\n    ],\n}\n</code></pre> <p>Available compressors:</p> Compressor Description <code>django_cachex.compressors.zlib.ZlibCompressor</code> zlib compression <code>django_cachex.compressors.gzip.GzipCompressor</code> gzip compression <code>django_cachex.compressors.lz4.Lz4Compressor</code> LZ4 (requires lz4) <code>django_cachex.compressors.lzma.LzmaCompressor</code> LZMA <code>django_cachex.compressors.zstd.ZstdCompressor</code> Zstandard (requires zstd) <p>Compression is only applied to values larger than <code>min_length</code> bytes (default: 256).</p>"},{"location":"user-guide/configuration/#connection-pool","title":"Connection Pool","text":"<pre><code>\"OPTIONS\": {\n    # Custom pool class\n    \"pool_class\": \"redis.ConnectionPool\",\n\n    # Pool size and options (passed to pool constructor)\n    \"max_connections\": 100,\n    \"retry_on_timeout\": True,\n\n    # Socket timeouts\n    \"socket_connect_timeout\": 5,\n    \"socket_timeout\": 5,\n}\n</code></pre>"},{"location":"user-guide/configuration/#parser","title":"Parser","text":"<pre><code>\"OPTIONS\": {\n    \"parser_class\": \"redis.connection.HiredisParser\",  # Faster parsing\n}\n</code></pre>"},{"location":"user-guide/configuration/#exception-handling","title":"Exception Handling","text":"<pre><code>\"OPTIONS\": {\n    # Ignore connection errors (return default/None instead)\n    \"ignore_exceptions\": True,\n\n    # Log ignored exceptions\n    \"log_ignored_exceptions\": True,\n}\n</code></pre> <p>Or globally via settings:</p> <pre><code>DJANGO_REDIS_IGNORE_EXCEPTIONS = True\nDJANGO_REDIS_LOG_IGNORED_EXCEPTIONS = True\nDJANGO_REDIS_LOGGER = \"myapp.cache\"  # Custom logger name\n</code></pre>"},{"location":"user-guide/configuration/#connection-lifecycle","title":"Connection Lifecycle","text":"<pre><code>\"OPTIONS\": {\n    # Close connections after each request\n    \"close_connection\": True,\n}\n</code></pre> <p>Or globally:</p> <pre><code>DJANGO_REDIS_CLOSE_CONNECTION = True\n</code></pre>"},{"location":"user-guide/configuration/#authentication","title":"Authentication","text":""},{"location":"user-guide/configuration/#password-in-url","title":"Password in URL","text":"<pre><code>\"LOCATION\": \"redis://user:password@127.0.0.1:6379/1\"\n</code></pre>"},{"location":"user-guide/configuration/#password-with-special-characters","title":"Password with Special Characters","text":"<p>For passwords with special characters, pass separately:</p> <pre><code>\"LOCATION\": \"redis://127.0.0.1:6379/1\",\n\"OPTIONS\": {\n    \"password\": \"my$pecial!password\",\n}\n</code></pre>"},{"location":"user-guide/configuration/#redis-acls","title":"Redis ACLs","text":"<pre><code>\"LOCATION\": \"redis://username@127.0.0.1:6379/1\",\n\"OPTIONS\": {\n    \"password\": \"password\",\n}\n</code></pre>"},{"location":"user-guide/configuration/#ssltls","title":"SSL/TLS","text":""},{"location":"user-guide/configuration/#basic-ssl","title":"Basic SSL","text":"<pre><code>\"LOCATION\": \"rediss://127.0.0.1:6379/1\"\n</code></pre>"},{"location":"user-guide/configuration/#self-signed-certificates","title":"Self-Signed Certificates","text":"<pre><code>\"LOCATION\": \"rediss://127.0.0.1:6379/1\",\n\"OPTIONS\": {\n    \"ssl_cert_reqs\": None,  # Disable verification\n}\n</code></pre>"},{"location":"user-guide/configuration/#custom-certificates","title":"Custom Certificates","text":"<pre><code>\"LOCATION\": \"rediss://127.0.0.1:6379/1\",\n\"OPTIONS\": {\n    \"ssl_ca_certs\": \"/path/to/ca.crt\",\n    \"ssl_certfile\": \"/path/to/client.crt\",\n    \"ssl_keyfile\": \"/path/to/client.key\",\n}\n</code></pre>"},{"location":"user-guide/configuration/#sentinel-configuration","title":"Sentinel Configuration","text":"<pre><code>CACHES = {\n    \"default\": {\n        \"BACKEND\": \"django_cachex.cache.RedisSentinelCache\",\n        \"LOCATION\": \"redis://mymaster/0\",  # Master name\n        \"OPTIONS\": {\n            \"sentinels\": [\n                (\"sentinel1.example.com\", 26379),\n                (\"sentinel2.example.com\", 26379),\n                (\"sentinel3.example.com\", 26379),\n            ],\n            \"sentinel_kwargs\": {\n                \"password\": \"sentinel-password\",\n            },\n        }\n    }\n}\n</code></pre>"},{"location":"user-guide/configuration/#cluster-configuration","title":"Cluster Configuration","text":"<pre><code>CACHES = {\n    \"default\": {\n        \"BACKEND\": \"django_cachex.cache.RedisClusterCache\",\n        \"LOCATION\": \"redis://127.0.0.1:7000\",\n    }\n}\n</code></pre>"},{"location":"user-guide/configuration/#timeouts","title":"Timeouts","text":""},{"location":"user-guide/configuration/#default-timeout","title":"Default Timeout","text":"<pre><code>\"TIMEOUT\": 300  # 5 minutes, None for no expiry\n</code></pre>"},{"location":"user-guide/configuration/#special-values","title":"Special Values","text":"<pre><code>cache.set(\"key\", \"value\", timeout=0)     # Delete immediately\ncache.set(\"key\", \"value\", timeout=None)  # Never expires\n</code></pre>"},{"location":"user-guide/configuration/#key-configuration","title":"Key Configuration","text":""},{"location":"user-guide/configuration/#key-prefix","title":"Key Prefix","text":"<pre><code>\"KEY_PREFIX\": \"myapp\"\n# Keys become: myapp:1:keyname\n</code></pre>"},{"location":"user-guide/configuration/#key-version","title":"Key Version","text":"<pre><code>\"VERSION\": 1\n# Keys become: prefix:1:keyname\n</code></pre>"},{"location":"user-guide/configuration/#custom-key-function","title":"Custom Key Function","text":"<pre><code>def my_key_func(key, key_prefix, version):\n    return f\"{key_prefix}:v{version}:{key}\"\n\nCACHES = {\n    \"default\": {\n        ...\n        \"KEY_FUNCTION\": \"myapp.cache.my_key_func\",\n    }\n}\n</code></pre>"},{"location":"user-guide/configuration/#complete-example","title":"Complete Example","text":"<pre><code>CACHES = {\n    \"default\": {\n        \"BACKEND\": \"django_cachex.cache.RedisCache\",\n        \"LOCATION\": \"redis://127.0.0.1:6379/1\",\n        \"TIMEOUT\": 300,\n        \"KEY_PREFIX\": \"myapp\",\n        \"VERSION\": 1,\n        \"OPTIONS\": {\n            # Serialization\n            \"serializer\": \"django_cachex.serializers.pickle.PickleSerializer\",\n\n            # Compression\n            \"compressor\": \"django_cachex.compressors.zstd.ZstdCompressor\",\n\n            # Connection pool\n            \"max_connections\": 50,\n            \"socket_connect_timeout\": 5,\n            \"socket_timeout\": 5,\n\n            # Exception handling\n            \"ignore_exceptions\": False,\n        }\n    }\n}\n</code></pre>"},{"location":"user-guide/sentinel/","title":"Redis Sentinel","text":"<p>django-cachex includes built-in support for Redis Sentinel for high availability.</p>"},{"location":"user-guide/sentinel/#basic-setup","title":"Basic Setup","text":"<p>Enable the Sentinel connection factory:</p> <pre><code>DJANGO_REDIS_CONNECTION_FACTORY = \"django_cachex.pool.SentinelConnectionFactory\"\n\nSENTINELS = [\n    (\"sentinel-1\", 26379),\n    (\"sentinel-2\", 26379),\n    (\"sentinel-3\", 26379),\n]\n\nCACHES = {\n    \"default\": {\n        \"BACKEND\": \"django_cachex.cache.RedisCache\",\n        \"LOCATION\": \"redis://service_name/db\",\n        \"OPTIONS\": {\n            \"CLIENT_CLASS\": \"django_cachex.client.SentinelClient\",\n            \"SENTINELS\": SENTINELS,\n        },\n    },\n}\n</code></pre>"},{"location":"user-guide/sentinel/#full-configuration-example","title":"Full Configuration Example","text":"<pre><code>DJANGO_REDIS_CONNECTION_FACTORY = \"django_cachex.pool.SentinelConnectionFactory\"\n\nSENTINELS = [\n    (\"sentinel-1\", 26379),\n    (\"sentinel-2\", 26379),\n    (\"sentinel-3\", 26379),\n]\n\nCACHES = {\n    # Full configuration with SentinelClient\n    \"default\": {\n        \"BACKEND\": \"django_cachex.cache.RedisCache\",\n        \"LOCATION\": \"redis://service_name/db\",\n        \"OPTIONS\": {\n            \"CLIENT_CLASS\": \"django_cachex.client.SentinelClient\",\n            \"SENTINELS\": SENTINELS,\n            \"SENTINEL_KWARGS\": {},  # Optional kwargs for Sentinel\n            \"CONNECTION_POOL_CLASS\": \"redis.sentinel.SentinelConnectionPool\",\n        },\n    },\n\n    # Minimal example with SentinelClient\n    \"minimal\": {\n        \"BACKEND\": \"django_cachex.cache.RedisCache\",\n        \"LOCATION\": \"redis://minimal_service_name/db\",\n        \"OPTIONS\": {\n            \"CLIENT_CLASS\": \"django_cachex.client.SentinelClient\",\n            \"SENTINELS\": SENTINELS,\n        },\n    },\n\n    # Using DefaultClient with primary/replica\n    \"other\": {\n        \"BACKEND\": \"django_cachex.cache.RedisCache\",\n        \"LOCATION\": [\n            \"redis://other_service_name/db?is_master=1\",\n            \"redis://other_service_name/db?is_master=0\",\n        ],\n        \"OPTIONS\": {\"SENTINELS\": SENTINELS},\n    },\n\n    # Read-only replicas\n    \"readonly\": {\n        \"BACKEND\": \"django_cachex.cache.RedisCache\",\n        \"LOCATION\": \"redis://readonly_service_name/db?is_master=0\",\n        \"OPTIONS\": {\"SENTINELS\": SENTINELS},\n    },\n}\n</code></pre>"},{"location":"user-guide/sentinel/#mixed-configuration","title":"Mixed Configuration","text":"<p>You can use both Sentinel and non-Sentinel caches:</p> <pre><code>SENTINELS = [\n    (\"sentinel-1\", 26379),\n    (\"sentinel-2\", 26379),\n    (\"sentinel-3\", 26379),\n]\n\nCACHES = {\n    # Sentinel-based cache\n    \"sentinel\": {\n        \"BACKEND\": \"django_cachex.cache.RedisCache\",\n        \"LOCATION\": \"redis://service_name/db\",\n        \"OPTIONS\": {\n            \"CLIENT_CLASS\": \"django_cachex.client.SentinelClient\",\n            \"SENTINELS\": SENTINELS,\n            \"CONNECTION_POOL_CLASS\": \"redis.sentinel.SentinelConnectionPool\",\n            \"CONNECTION_FACTORY\": \"django_cachex.pool.SentinelConnectionFactory\",\n        },\n    },\n\n    # Standard Redis cache\n    \"default\": {\n        \"BACKEND\": \"django_cachex.cache.RedisCache\",\n        \"LOCATION\": \"redis://127.0.0.1:6379/1\",\n        \"OPTIONS\": {\n            \"CLIENT_CLASS\": \"django_cachex.client.DefaultClient\",\n        },\n    },\n}\n</code></pre>"},{"location":"user-guide/sentinel/#url-parameters","title":"URL Parameters","text":"<p>When using Sentinel with the DefaultClient:</p> <ul> <li><code>is_master=1</code> - Connect to primary</li> <li><code>is_master=0</code> - Connect to replica</li> </ul>"},{"location":"user-guide/serializers/","title":"Serializers","text":"<p>django-cachex supports pluggable serializers for data before sending to Redis.</p>"},{"location":"user-guide/serializers/#pickle-serializer-default","title":"Pickle Serializer (Default)","text":"<p>The default serializer uses Python's <code>pickle</code> module:</p> <pre><code>CACHES = {\n    \"default\": {\n        \"BACKEND\": \"django_cachex.cache.RedisCache\",\n        \"LOCATION\": \"redis://127.0.0.1:6379/1\",\n        \"OPTIONS\": {\n            \"CLIENT_CLASS\": \"django_cachex.client.DefaultClient\",\n            # Uses pickle by default\n        }\n    }\n}\n</code></pre>"},{"location":"user-guide/serializers/#configure-pickle-version","title":"Configure Pickle Version","text":"<pre><code>CACHES = {\n    \"default\": {\n        \"BACKEND\": \"django_cachex.cache.RedisCache\",\n        \"LOCATION\": \"redis://127.0.0.1:6379/1\",\n        \"OPTIONS\": {\n            \"PICKLE_VERSION\": -1  # Highest protocol available\n        }\n    }\n}\n</code></pre>"},{"location":"user-guide/serializers/#json-serializer","title":"JSON Serializer","text":"<p>For JSON-serializable data only:</p> <pre><code>CACHES = {\n    \"default\": {\n        \"BACKEND\": \"django_cachex.cache.RedisCache\",\n        \"LOCATION\": \"redis://127.0.0.1:6379/1\",\n        \"OPTIONS\": {\n            \"CLIENT_CLASS\": \"django_cachex.client.DefaultClient\",\n            \"SERIALIZER\": \"django_cachex.serializers.json.JSONSerializer\",\n        }\n    }\n}\n</code></pre>"},{"location":"user-guide/serializers/#msgpack-serializer","title":"MsgPack Serializer","text":"<p>Requires the <code>msgpack</code> library:</p> <pre><code>pip install msgpack\n</code></pre> <pre><code>CACHES = {\n    \"default\": {\n        \"BACKEND\": \"django_cachex.cache.RedisCache\",\n        \"LOCATION\": \"redis://127.0.0.1:6379/1\",\n        \"OPTIONS\": {\n            \"CLIENT_CLASS\": \"django_cachex.client.DefaultClient\",\n            \"SERIALIZER\": \"django_cachex.serializers.msgpack.MSGPackSerializer\",\n        }\n    }\n}\n</code></pre>"},{"location":"user-guide/serializers/#serializer-fallback-migration-support","title":"Serializer Fallback (Migration Support)","text":"<p>When migrating from one serializer to another, you can specify a list of serializers. The first serializer is used for writing new data, while all serializers are tried in order when reading until one succeeds.</p> <p>This allows safe migration between serialization formats without data loss:</p> <pre><code>CACHES = {\n    \"default\": {\n        \"BACKEND\": \"django_cachex.cache.RedisCache\",\n        \"LOCATION\": \"redis://127.0.0.1:6379/1\",\n        \"OPTIONS\": {\n            # First serializer used for writing, all tried for reading\n            \"SERIALIZER\": [\n                \"django_cachex.serializers.json.JSONSerializer\",  # New format\n                \"django_cachex.serializers.pickle.PickleSerializer\",  # Old format\n            ],\n        }\n    }\n}\n</code></pre>"},{"location":"user-guide/serializers/#migration-example","title":"Migration Example","text":"<ol> <li> <p>Before migration - using pickle:    <pre><code>\"SERIALIZER\": \"django_cachex.serializers.pickle.PickleSerializer\"\n</code></pre></p> </li> <li> <p>During migration - write JSON, read both:    <pre><code>\"SERIALIZER\": [\n    \"django_cachex.serializers.json.JSONSerializer\",\n    \"django_cachex.serializers.pickle.PickleSerializer\",\n]\n</code></pre></p> </li> <li> <p>After migration - all data refreshed with JSON:    <pre><code>\"SERIALIZER\": \"django_cachex.serializers.json.JSONSerializer\"\n</code></pre></p> </li> </ol>"},{"location":"user-guide/serializers/#how-it-works","title":"How It Works","text":"<p>When deserializing, each serializer is tried in order. If deserialization fails, the next serializer is tried. This continues until one succeeds or all fail.</p>"},{"location":"user-guide/serializers/#custom-serializer","title":"Custom Serializer","text":"<p>Create a custom serializer by implementing <code>dumps</code> and <code>loads</code> methods:</p> <pre><code>from django_cachex.serializers.base import BaseSerializer\nfrom django_cachex.exceptions import SerializerError\n\nclass MySerializer(BaseSerializer):\n    def dumps(self, value):\n        # Convert value to bytes\n        return my_encode(value)\n\n    def loads(self, value):\n        # Convert bytes to value\n        try:\n            return my_decode(value)\n        except MyDecodeError as e:\n            raise SerializerError from e\n</code></pre> <p>Note: Custom serializers should raise <code>SerializerError</code> on deserialization failure to enable proper fallback behavior when using multiple serializers.</p> <p>Then configure:</p> <pre><code>CACHES = {\n    \"default\": {\n        \"BACKEND\": \"django_cachex.cache.RedisCache\",\n        \"LOCATION\": \"redis://127.0.0.1:6379/1\",\n        \"OPTIONS\": {\n            \"SERIALIZER\": \"myapp.serializers.MySerializer\",\n        }\n    }\n}\n</code></pre>"}]}